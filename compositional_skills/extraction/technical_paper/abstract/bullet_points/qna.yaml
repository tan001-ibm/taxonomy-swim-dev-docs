created_by: IBM
seed_examples:
- answer: 'Abstract summary:

    - Synthetic data generation requires attention to the downstream user requirements
    to have full utility.

    - The authors introduce a post-processing technique that improves utility while
    preserving data privacy and quality.

    - The approach consistently improves the utility of synthetic data across multiple
    benchmark datasets and state-of-the-art synthetic data generation algorithms.

    '
  context: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: 'Give a summary of the abstract in bullets.

    '
- answer: 'Here are the author''s emails:

    - hao@ibm.com

    - shiv.sr@ibm.com

    - john.l.henning@ibm.com

    - kristjan.h.greenewald@ibm.com

    - akash.srivastava@ibm.com

    '
  context: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: 'Provide a bulleted list of the author''s emails.

    '
- answer: "Here's some recent work in the area of synthetic data generation:\n- The\
    \ U.S. National Institute of Standards and Technology (NIST) has emphasized its\
    \ significance by hosting a series of competitions [RTMT21, MMS21].\n- There is\
    \ also significant work introducing new DP synthetic data generation mechanisms.\
    \ Methods include\n    - GAN-based [XLW+18, BJWW+19, JYVDS19, TWB+19]\n    - Marginal-based\
    \ [ZCP+17, MSM19, MMS21]\n    - Workload-based [VTB+20, ABK+21, LVW21, MMSM22,\
    \ VAA+22]\n"
  context: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: 'What has been done recently in the area of synthetic data generation?
    Give it to me in bullets with their associated citations.

    '
task_description: 'extracting content from a technical paper and providing it in bulleted
  format

  '
