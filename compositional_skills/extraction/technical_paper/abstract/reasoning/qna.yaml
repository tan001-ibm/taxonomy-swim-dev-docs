created_by: IBM
seed_examples:
- answer: 'This abstract has several parts. First, the authors describe the problems
    with existing approaches. They then outline why it is a problem. The next step
    is to describe the novel approach the paper takes. The authors describe their
    results and their implications.

    '
  context: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: 'What is the structure of the abstract?

    '
- answer: 'Synthetic data generation, post-processing techniques, data privacy

    The primary topic of this paper is about synthetic data generation. The novel
    approach is around using a novel post-processing technique for the synthetic data
    generation. The benefit of this approach is to maintain data privacy while maintaining
    utility.

    '
  context: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: List 3 tags for this paper.
- answer: "People interested in synthetic data generation because of privacy concerns.\
    \ \nThe authors describe interested parties as broad as the US Census and large\
    \ corporations because those groups have interest in protecting data privacy.\
    \   \n"
  context: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: 'Who might want to read this paper that isn''t specifically doing research
    in this area?

    '
task_description: 'answering questions about a provided technical paper

  '
