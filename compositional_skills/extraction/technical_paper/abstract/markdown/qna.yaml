created_by: IBM
seed_examples:
- answer: '```

    | Author                 | Affiliation           |

    | ---------------------- | --------------------- |

    | Hao Wang               | MIT-IBM Watson AI Lab |

    | Shivchander Sudalairaj | MIT-IBM Watson AI Lab |

    | John Henning           | MIT-IBM Watson AI Lab |

    | Kristjan Greenewald    | MIT-IBM Watson AI Lab |

    | Akash Srivastava       | MIT-IBM Watson AI Lab |

    ```

    '
  context: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: 'Create a table in markdown of the authors and where they''re from.

    '
- answer: '```

    | Location                   | Citations                            |

    | -------------------------- | ------------------------------------ |

    | US Census                  | [Abo18]                              |

    | Various Large Corporations | [App17, Fac20, RE19, HBMAL19, IBM23] |

    ```

    '
  context: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: Create a table in markdown listing the place and citations related to
    where differential privacy has been used.
- answer: '```

    | Technique      | Citation                                |

    | -------------- | --------------------------------------- |

    | GAN-based      | [XLW+18, BJWW+19, JYVDS19, TWB+19]      |

    | Marginal-based | [ZCP+17, MSM19, MMS21]                  |

    | Workload-based | [VTB+20, ABK+21, LVW21, MMSM22, VAA+22] |

    ```


    '
  context: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: 'Create a table in markdown of each type of synthetic data generation
    technique listed in the literature review. Make sure the table has 2 columns.
    The first is the technique and the second is the citations. Make sure all the
    citations for each technique fit in the 2nd column with a comma separating each
    - don''t make a new column for each citation.

    '
task_description: 'extracting content from a technical paper and providing it in markdown
  format

  '
