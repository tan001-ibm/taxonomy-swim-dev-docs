created_by: IBM
seed_examples:
- answer: "\\### 1.1 Related Work\n\nDP synthetic data generation mechanisms. Generating\
    \ synthetic data using DP mechanisms is an active area of research [see e.g.,\
    \ HLM12, BLR13, GAH + 14, CXZX15, BSG17, AZK + 19, UV20, GMHI20, TMH + 21, VAA\
    \ + 22, BSV22]. Along this line of work, the closest ones to ours are workload-aware\
    \ methods [VTB + 20, ABK + 21, MMSM22, LVW21], which aim to ensure that the synthetic\
    \ data perform well on a collection of queries. Our work differs in three key\
    \ features. First, all existing approaches focus on generating private synthetic\
    \ data from scratch, while we aim to post-process synthetic data to downweight\
    \ samples that do not accurately represent the real data under the specified utility\
    \ measures. As a result, our approach is more efficient as it does not need to\
    \ fit a graphical model [MMSM22] or a neural network [LVW21] to represent the\
    \ data distribution, and it is more extendable, allowing a single synthetic dataset\
    \ to be quickly post-processed multiple times for different sets of utility measures\
    \ as needed by downstream users. Second, some existing work may not scale well\
    \ to large datasets as they either require solving an integer program multiple\
    \ times [VTB + 20] or need to solve a large-scale optimization problem [ABK +\
    \ 21]. In contrast, our approach is highly scalable, as it only requires solving\
    \ a convex program whose number of variables is equal to the number of specified\
    \ utility measures. Third, existing work often evaluates the quality of the synthetic\
    \ data by how well it preserves key statistics (e.g., 3-way marginals) of the\
    \ real data. In contrast, in our experiments, we evaluate our approach on the\
    \ more stringent and realistic test of training various downstream ML models on\
    \ the synthetic data and measuring their performance on real test data. The experimental\
    \ results demonstrate that our approach can enhance the utility of synthetic data\
    \ on selected measures without compromising their downstream quality.\n\nPublic\
    \ data assisted methods/Post-processing methods. Our work introduces a post-processing\
    \ procedure for improving the utility of a given synthetic dataset based on selected\
    \ measures. As a special case, our approach can be applied to post-process publicly\
    \ available datasets. In this regard, this work is related to public-data-assisted\
    \ methods [see e.g., LVS + 21, LVW21], which leverage public data for saving privacy\
    \ budgets. We extend Algorithm 1 in [LVS + 21] by formalizing the preservation\
    \ of (noisy) utility measures as a constrained optimization problem, rather than\
    \ minimizing the corresponding Lagrangian function. We further establish strong\
    \ duality and propose a stochastic first-order method for solving this constrained\
    \ optimization efficiently. We extend Algorithm 4 in [LVW21] by allowing any non-negative\
    \ violation tolerance (i.e., any \u03B3 \u2265 0 in (3b)) compared with \u03B3\
    \ = 0 in [LVW21]. This extension offers increased flexibility, as users can now\
    \ select various values of \u03B3 to navigate the trade-off between minimizing\
    \ the distortion of the synthetic data and enhancing their utility on selected\
    \ measures. Moreover, our experiments show that setting \u03B3 to be a small positive\
    \ number (e.g., \u03B3 = 1 e-5) consistently outperforms when \u03B3 = 0. Finally,\
    \ our work is related with [NWD20], which proposes to post-process outputs from\
    \ differentially private GAN-based models for improving the quality of the generated\
    \ synthetic data. However, their method is tailored to GAN-based privacy mechanisms\
    \ while our approach is model-agnostic. This versatility is crucial, given that\
    \ marginal-based and workload-based mechanisms often yield higher quality synthetic\
    \ tabular data, as evidenced by benchmark experiments in [TMH + 21]. Our experiments\
    \ indicate that our method consistently improves the utility of synthetic data\
    \ produced by all kinds of privacy mechanisms, even when the initial synthetic\
    \ data are of high quality.\n\n\\### 2 Preliminaries and Problem Formulation\n\
    \nIn this section, we review differential privacy and provide an overview of our\
    \ problem setup.\n\n\\### 2.1 Differential Privacy\n\nWe first recall the definition\
    \ of differential privacy (DP) [DR14].\n\nDefinition 1. $^{A randomized mechanism}$M\
    \ : X n \u2192 R satisfies (\u03F5 \u21AA \u03B4)-differential privacy, if for\
    \ any $^{adjacent datasets}$D $^{and}$D ', which only differ in one individual's\
    \ record, and all possible outputs $^{from the mechanism}$O \u2286 R, we have\n\
    \nDP has two important properties: post-processing immunity and composition rule.\
    \ Specifically, if M : X n \u2192 R satisfies (\u03F5 \u21AA \u03B4)-DP and g\
    \ : R \u2192 R ' is any randomized (or deterministic) function, then\n\n"
  context: "## 1.1 Related Work\n\nDP synthetic data generation mechanisms. Generating\
    \ synthetic data using DP mechanisms is an active area of research [see e.g.,\
    \ HLM12, BLR13, GAH + 14, CXZX15, BSG17, AZK + 19, UV20, GMHI20, TMH + 21, VAA\
    \ + 22, BSV22]. Along this line of work, the closest ones to ours are workload-aware\
    \ methods [VTB + 20, ABK + 21, MMSM22, LVW21], which aim to ensure that the synthetic\
    \ data perform well on a collection of queries. Our work differs in three key\
    \ features. First, all existing approaches focus on generating private synthetic\
    \ data from scratch, while we aim to post-process synthetic data to downweight\
    \ samples that do not accurately represent the real data under the specified utility\
    \ measures. As a result, our approach is more efficient as it does not need to\
    \ fit a graphical model [MMSM22] or a neural network [LVW21] to represent the\
    \ data distribution, and it is more extendable, allowing a single synthetic dataset\
    \ to be quickly post-processed multiple times for different sets of utility measures\
    \ as needed by downstream users. Second, some existing work may not scale well\
    \ to large datasets as they either require solving an integer program multiple\
    \ times [VTB + 20] or need to solve a large-scale optimization problem [ABK +\
    \ 21]. In contrast, our approach is highly scalable, as it only requires solving\
    \ a convex program whose number of variables is equal to the number of specified\
    \ utility measures. Third, existing work often evaluates the quality of the synthetic\
    \ data by how well it preserves key statistics (e.g., 3-way marginals) of the\
    \ real data. In contrast, in our experiments, we evaluate our approach on the\
    \ more stringent and realistic test of training various downstream ML models on\
    \ the synthetic data and measuring their performance on real test data. The experimental\
    \ results demonstrate that our approach can enhance the utility of synthetic data\
    \ on selected measures without compromising their downstream quality.\n\nPublic\
    \ data assisted methods/Post-processing methods. Our work introduces a post-processing\
    \ procedure for improving the utility of a given synthetic dataset based on selected\
    \ measures. As a special case, our approach can be applied to post-process publicly\
    \ available datasets. In this regard, this work is related to public-data-assisted\
    \ methods [see e.g., LVS + 21, LVW21], which leverage public data for saving privacy\
    \ budgets. We extend Algorithm 1 in [LVS + 21] by formalizing the preservation\
    \ of (noisy) utility measures as a constrained optimization problem, rather than\
    \ minimizing the corresponding Lagrangian function. We further establish strong\
    \ duality and propose a stochastic first-order method for solving this constrained\
    \ optimization efficiently. We extend Algorithm 4 in [LVW21] by allowing any non-negative\
    \ violation tolerance (i.e., any \u03B3 \u2265 0 in (3b)) compared with \u03B3\
    \ = 0 in [LVW21]. This extension offers increased flexibility, as users can now\
    \ select various values of \u03B3 to navigate the trade-off between minimizing\
    \ the distortion of the synthetic data and enhancing their utility on selected\
    \ measures. Moreover, our experiments show that setting \u03B3 to be a small positive\
    \ number (e.g., \u03B3 = 1 e-5) consistently outperforms when \u03B3 = 0. Finally,\
    \ our work is related with [NWD20], which proposes to post-process outputs from\
    \ differentially private GAN-based models for improving the quality of the generated\
    \ synthetic data. However, their method is tailored to GAN-based privacy mechanisms\
    \ while our approach is model-agnostic. This versatility is crucial, given that\
    \ marginal-based and workload-based mechanisms often yield higher quality synthetic\
    \ tabular data, as evidenced by benchmark experiments in [TMH + 21]. Our experiments\
    \ indicate that our method consistently improves the utility of synthetic data\
    \ produced by all kinds of privacy mechanisms, even when the initial synthetic\
    \ data are of high quality.\n\n## 2 Preliminaries and Problem Formulation\n\n\
    In this section, we review differential privacy and provide an overview of our\
    \ problem setup.\n\n## 2.1 Differential Privacy\n\nWe first recall the definition\
    \ of differential privacy (DP) [DR14].\n\nDefinition 1. $^{A randomized mechanism}$M\
    \ : X n \u2192 R satisfies (\u03F5 \u21AA \u03B4)-differential privacy, if for\
    \ any $^{adjacent datasets}$D $^{and}$D ', which only differ in one individual's\
    \ record, and all possible outputs $^{from the mechanism}$O \u2286 R, we have\n\
    \nDP has two important properties: post-processing immunity and composition rule.\
    \ Specifically, if M : X n \u2192 R satisfies (\u03F5 \u21AA \u03B4)-DP and g\
    \ : R \u2192 R ' is any randomized (or deterministic) function, then\n"
  question: 'Update this markdown document by changing headers from level 2 to level
    3.

    '
- answer: "| Reference | Count |\n| --------- | ----- |\n| HLM12\_\_| 1\_\_|\n| BLR13\_\
    \_| 1\_\_|\n| GAH + 14\_| 1\_\_|\n| CXZX15\_\_| 1\_\_|\n| BSG17\_\_| 1\_\_|\n\
    | AZK + 19\_| 1\_\_|\n| UV20\_\_\_| 1\_\_|\n| GMHI20\_\_| 1\_\_|\n| TMH + 21\_\
    | 1\_\_|\n| VAA + 22\_| 1\_\_|\n| BSV22\_\_| 1\_\_|\n| VTB + 20\_| 2\_\_|\n| ABK\
    \ + 21\_| 2\_\_|\n| MMSM22\_\_| 2\_\_|\n| LVW21\_\_| 5\_\_|\n| LVS + 21\_| 2\_\
    \_|\n| NWD20\_\_| 1\_\_|\n| TMH + 21\_| 1\_\_|\n| DR14\_\_\_| 1\_\_|\n"
  context: "## 1.1 Related Work\n\nDP synthetic data generation mechanisms. Generating\
    \ synthetic data using DP mechanisms is an active area of research [see e.g.,\
    \ HLM12, BLR13, GAH + 14, CXZX15, BSG17, AZK + 19, UV20, GMHI20, TMH + 21, VAA\
    \ + 22, BSV22]. Along this line of work, the closest ones to ours are workload-aware\
    \ methods [VTB + 20, ABK + 21, MMSM22, LVW21], which aim to ensure that the synthetic\
    \ data perform well on a collection of queries. Our work differs in three key\
    \ features. First, all existing approaches focus on generating private synthetic\
    \ data from scratch, while we aim to post-process synthetic data to downweight\
    \ samples that do not accurately represent the real data under the specified utility\
    \ measures. As a result, our approach is more efficient as it does not need to\
    \ fit a graphical model [MMSM22] or a neural network [LVW21] to represent the\
    \ data distribution, and it is more extendable, allowing a single synthetic dataset\
    \ to be quickly post-processed multiple times for different sets of utility measures\
    \ as needed by downstream users. Second, some existing work may not scale well\
    \ to large datasets as they either require solving an integer program multiple\
    \ times [VTB + 20] or need to solve a large-scale optimization problem [ABK +\
    \ 21]. In contrast, our approach is highly scalable, as it only requires solving\
    \ a convex program whose number of variables is equal to the number of specified\
    \ utility measures. Third, existing work often evaluates the quality of the synthetic\
    \ data by how well it preserves key statistics (e.g., 3-way marginals) of the\
    \ real data. In contrast, in our experiments, we evaluate our approach on the\
    \ more stringent and realistic test of training various downstream ML models on\
    \ the synthetic data and measuring their performance on real test data. The experimental\
    \ results demonstrate that our approach can enhance the utility of synthetic data\
    \ on selected measures without compromising their downstream quality.\n\nPublic\
    \ data assisted methods/Post-processing methods. Our work introduces a post-processing\
    \ procedure for improving the utility of a given synthetic dataset based on selected\
    \ measures. As a special case, our approach can be applied to post-process publicly\
    \ available datasets. In this regard, this work is related to public-data-assisted\
    \ methods [see e.g., LVS + 21, LVW21], which leverage public data for saving privacy\
    \ budgets. We extend Algorithm 1 in [LVS + 21] by formalizing the preservation\
    \ of (noisy) utility measures as a constrained optimization problem, rather than\
    \ minimizing the corresponding Lagrangian function. We further establish strong\
    \ duality and propose a stochastic first-order method for solving this constrained\
    \ optimization efficiently. We extend Algorithm 4 in [LVW21] by allowing any non-negative\
    \ violation tolerance (i.e., any \u03B3 \u2265 0 in (3b)) compared with \u03B3\
    \ = 0 in [LVW21]. This extension offers increased flexibility, as users can now\
    \ select various values of \u03B3 to navigate the trade-off between minimizing\
    \ the distortion of the synthetic data and enhancing their utility on selected\
    \ measures. Moreover, our experiments show that setting \u03B3 to be a small positive\
    \ number (e.g., \u03B3 = 1 e-5) consistently outperforms when \u03B3 = 0. Finally,\
    \ our work is related with [NWD20], which proposes to post-process outputs from\
    \ differentially private GAN-based models for improving the quality of the generated\
    \ synthetic data. However, their method is tailored to GAN-based privacy mechanisms\
    \ while our approach is model-agnostic. This versatility is crucial, given that\
    \ marginal-based and workload-based mechanisms often yield higher quality synthetic\
    \ tabular data, as evidenced by benchmark experiments in [TMH + 21]. Our experiments\
    \ indicate that our method consistently improves the utility of synthetic data\
    \ produced by all kinds of privacy mechanisms, even when the initial synthetic\
    \ data are of high quality.\n\n## 2 Preliminaries and Problem Formulation\n\n\
    In this section, we review differential privacy and provide an overview of our\
    \ problem setup.\n\n## 2.1 Differential Privacy\n\nWe first recall the definition\
    \ of differential privacy (DP) [DR14].\n\nDefinition 1. $^{A randomized mechanism}$M\
    \ : X n \u2192 R satisfies (\u03F5 \u21AA \u03B4)-differential privacy, if for\
    \ any $^{adjacent datasets}$D $^{and}$D ', which only differ in one individual's\
    \ record, and all possible outputs $^{from the mechanism}$O \u2286 R, we have\n\
    \nDP has two important properties: post-processing immunity and composition rule.\
    \ Specifically, if M : X n \u2192 R satisfies (\u03F5 \u21AA \u03B4)-DP and g\
    \ : R \u2192 R ' is any randomized (or deterministic) function, then\n"
  question: Extract all references from the document (such as HLM12, ABK + 21, LVW21,
    etc) and provide the count of each reference in a markdown table format.
- answer: '```

    | Section | Title                                 |

    | ------- | ------------------------------------- |

    | 1.1     | Related Work                          |

    | 2       | Preliminaries and Problem Formulation |

    | 2.1     | Differential Privacy                  |

    ```


    '
  context: "## 1.1 Related Work\n\nDP synthetic data generation mechanisms. Generating\
    \ synthetic data using DP mechanisms is an active area of research [see e.g.,\
    \ HLM12, BLR13, GAH + 14, CXZX15, BSG17, AZK + 19, UV20, GMHI20, TMH + 21, VAA\
    \ + 22, BSV22]. Along this line of work, the closest ones to ours are workload-aware\
    \ methods [VTB + 20, ABK + 21, MMSM22, LVW21], which aim to ensure that the synthetic\
    \ data perform well on a collection of queries. Our work differs in three key\
    \ features. First, all existing approaches focus on generating private synthetic\
    \ data from scratch, while we aim to post-process synthetic data to downweight\
    \ samples that do not accurately represent the real data under the specified utility\
    \ measures. As a result, our approach is more efficient as it does not need to\
    \ fit a graphical model [MMSM22] or a neural network [LVW21] to represent the\
    \ data distribution, and it is more extendable, allowing a single synthetic dataset\
    \ to be quickly post-processed multiple times for different sets of utility measures\
    \ as needed by downstream users. Second, some existing work may not scale well\
    \ to large datasets as they either require solving an integer program multiple\
    \ times [VTB + 20] or need to solve a large-scale optimization problem [ABK +\
    \ 21]. In contrast, our approach is highly scalable, as it only requires solving\
    \ a convex program whose number of variables is equal to the number of specified\
    \ utility measures. Third, existing work often evaluates the quality of the synthetic\
    \ data by how well it preserves key statistics (e.g., 3-way marginals) of the\
    \ real data. In contrast, in our experiments, we evaluate our approach on the\
    \ more stringent and realistic test of training various downstream ML models on\
    \ the synthetic data and measuring their performance on real test data. The experimental\
    \ results demonstrate that our approach can enhance the utility of synthetic data\
    \ on selected measures without compromising their downstream quality.\n\nPublic\
    \ data assisted methods/Post-processing methods. Our work introduces a post-processing\
    \ procedure for improving the utility of a given synthetic dataset based on selected\
    \ measures. As a special case, our approach can be applied to post-process publicly\
    \ available datasets. In this regard, this work is related to public-data-assisted\
    \ methods [see e.g., LVS + 21, LVW21], which leverage public data for saving privacy\
    \ budgets. We extend Algorithm 1 in [LVS + 21] by formalizing the preservation\
    \ of (noisy) utility measures as a constrained optimization problem, rather than\
    \ minimizing the corresponding Lagrangian function. We further establish strong\
    \ duality and propose a stochastic first-order method for solving this constrained\
    \ optimization efficiently. We extend Algorithm 4 in [LVW21] by allowing any non-negative\
    \ violation tolerance (i.e., any \u03B3 \u2265 0 in (3b)) compared with \u03B3\
    \ = 0 in [LVW21]. This extension offers increased flexibility, as users can now\
    \ select various values of \u03B3 to navigate the trade-off between minimizing\
    \ the distortion of the synthetic data and enhancing their utility on selected\
    \ measures. Moreover, our experiments show that setting \u03B3 to be a small positive\
    \ number (e.g., \u03B3 = 1 e-5) consistently outperforms when \u03B3 = 0. Finally,\
    \ our work is related with [NWD20], which proposes to post-process outputs from\
    \ differentially private GAN-based models for improving the quality of the generated\
    \ synthetic data. However, their method is tailored to GAN-based privacy mechanisms\
    \ while our approach is model-agnostic. This versatility is crucial, given that\
    \ marginal-based and workload-based mechanisms often yield higher quality synthetic\
    \ tabular data, as evidenced by benchmark experiments in [TMH + 21]. Our experiments\
    \ indicate that our method consistently improves the utility of synthetic data\
    \ produced by all kinds of privacy mechanisms, even when the initial synthetic\
    \ data are of high quality.\n\n## 2 Preliminaries and Problem Formulation\n\n\
    In this section, we review differential privacy and provide an overview of our\
    \ problem setup.\n\n## 2.1 Differential Privacy\n\nWe first recall the definition\
    \ of differential privacy (DP) [DR14].\n\nDefinition 1. $^{A randomized mechanism}$M\
    \ : X n \u2192 R satisfies (\u03F5 \u21AA \u03B4)-differential privacy, if for\
    \ any $^{adjacent datasets}$D $^{and}$D ', which only differ in one individual's\
    \ record, and all possible outputs $^{from the mechanism}$O \u2286 R, we have\n\
    \nDP has two important properties: post-processing immunity and composition rule.\
    \ Specifically, if M : X n \u2192 R satisfies (\u03F5 \u21AA \u03B4)-DP and g\
    \ : R \u2192 R ' is any randomized (or deterministic) function, then\n"
  question: 'Create a table of contents for this document. Table should be in markdown
    format.

    '
- answer: '| Method | Citation |

    |---|---|

    | AIM | [MMSM22] |

    | MST | [MMS21] |

    | DPCTGAN | [RLP + 20] |

    | PATECTGAN | [RLP + 20] |

    | GEM | [LVW21] |

    '
  context: "data across multiple datasets and state-of-the-art privacy mechanisms.\
    \ Additionally, it achieves this without degrading the performance of downstream\
    \ models or statistical metrics. We provide additional experimental results and\
    \ implementation details in Appendix C.\n\nBenchmark. We evaluate our algorithm\
    \ on four benchmark datasets: Adult, Bank, Mushroom, and Shopping, which are from\
    \ the UCI machine learning repository [DG17]. All the datasets have a target variable\
    \ that can be used for a downstream prediction task. We use four existing DP mechanisms-AIM\
    \ [MMSM22], MST [MMS21], DPCTGAN [RLP + 20], and PATECTGAN [RLP + 20]to generate\
    \ private synthetic data. Among these DP mechanisms, AIM is a workload-based method;\
    \ MST is a marginal-based method; DPCTGAN and PATECTGAN are GAN-based methods.\
    \ All of their implementations are from the OpenDP library [Sma23]. To demonstrate\
    \ the scalability of our approach, we conduct an additional experiment on the\
    \ home-credit dataset [MOK18]. This dataset has 307,511 data points and 104 features.\
    \ We apply GEM [LVW21] to this high-dimensional dataset for generating synthetic\
    \ data. We pre-process each dataset to convert categorical columns into numerical\
    \ features and standardize all features to the range [0 \u21AA 1].\n\nWe clarify\
    \ that our objective is not to compare the quality of synthetic data generated\
    \ by these DP mechanisms (for a benchmark evaluation, please refer to [TMH + 21]),\
    \ but to demonstrate how our post-processing method can consistently improve the\
    \ utility of synthetic data generated from these different DP mechanisms.\n\n\
    Setup. We compare synthetic data produced by different privacy mechanisms with\
    \ \u03F5 \u2208 \xB6 2 \u21AA 4 \u2666 against the post-processed synthetic data\
    \ that are generated by applying our post-processing technique with \u03F5$_{post}$\
    \ =1 to synthetic data generated from privacy mechanisms with \u03F5 \u2208 \xB6\
    \ 1 \u21AA 3 \u2666. For UCI datasets, we select 5 features, including the target\
    \ variable, from the synthetic data that have the highest absolute correlation\
    \ with the target variable. These features are chosen as they have a higher influence\
    \ on downstream prediction tasks. The set of these features is denoted by S \u2286\
    \ [d]. Next, we define the utility measures as the first-order and second-order\
    \ moment queries among the features in S : Q = \xB6 q$_{i}$ (x) = x$_{i}$ \u2666\
    \ i \u2208 S \u222A \xB6 q$_{i\u21AAj}$ (x) = x$_{i}$x$_{j}$ \u2666 i\u21AAj \u2208\
    \ S. For home-credit dataset, we follow the same setup but choosing 10 features.\n\
    \nWe apply the Gaussian mechanism with (\u03F5$_{post}$ =1 \u21AA \u03B4$_{post}$\
    \ =1 \u25C1n $^{2}$) to estimate utility measures from the real data, where n\
    \ denotes the number of real data points. Finally, we apply Algorithm 1 with \u03B3\
    \ = 1 e-5, a batch size of 256 for UCI datasets and 4096 for home-credit, and\
    \ 200 epochs to compute the optimal resampling weights, which are then used to\
    \ resample from the synthetic data with the same sample size. We repeat our experiment\
    \ 5 times to obtain an error bar for each evaluation measure.\n\nEvaluation measure.\
    \ We provide evaluation metrics for assessing the quality of synthetic data after\
    \ post-processing. Our first metric, utility improvement, is defined as:\n\nThe\
    \ range of this metric is (-\u221E \u21AA 1], where a value of 1 indicates a perfect\
    \ alignment between the correlation matrix of the post-processed data and the\
    \ real data.\n\nTo assess the downstream quality of synthetic data, we train predictive\
    \ models using the synthetic data and then test their performance on real data.\
    \ Specifically, we split the real data, using 80% for generating synthetic data\
    \ and setting aside 20% to evaluate the performance of predictive models. We use\
    \ the synthetic data to train a logistic regression classifier to predict the\
    \ target variable based on other features. Then we apply this classifier to real\
    \ data and calculate its F1 score. We use the function BinaryLogisticRegression\
    \ from SDMetrics library [Dat23] to implement this process.\n\nWe compute two\
    \ statistical measures to quantify the similarity between synthetic and real data\
    \ distributions. The first measure is the average Jensen-Shannon distance between\
    \ the marginal distributions of synthetic and real data, which ranges from 0 (identical\
    \ distribution) to 1 (totally different distributions). The second measure is\
    \ the average inverse KL-divergence between the marginal distributions of synthetic\
    \ and real data, which ranges from 0 (totally different distributions) to 1 (identical\
    \ distribution). These statistical measures are implemented by using synthcity\
    \ library [QCvdS23].\n"
  question: "List the synthetic dataset generation methods referenced in the paper\
    \ and the corresponding citation (if exists in the text). Please use Markdown\
    \ format. \n"
- answer: "| Parameter | Value |\n|---|---|\n| \u03B3 | 1e-5 |\n| Batch size (UCI)\
    \ | 256 |\n| Batch size (home-credit) | 4096 |\n| Epochs | 200 |\n| Experiment\
    \ repetitions | 5 |\n"
  context: "data across multiple datasets and state-of-the-art privacy mechanisms.\
    \ Additionally, it achieves this without degrading the performance of downstream\
    \ models or statistical metrics. We provide additional experimental results and\
    \ implementation details in Appendix C.\n\nBenchmark. We evaluate our algorithm\
    \ on four benchmark datasets: Adult, Bank, Mushroom, and Shopping, which are from\
    \ the UCI machine learning repository [DG17]. All the datasets have a target variable\
    \ that can be used for a downstream prediction task. We use four existing DP mechanisms-AIM\
    \ [MMSM22], MST [MMS21], DPCTGAN [RLP + 20], and PATECTGAN [RLP + 20]to generate\
    \ private synthetic data. Among these DP mechanisms, AIM is a workload-based method;\
    \ MST is a marginal-based method; DPCTGAN and PATECTGAN are GAN-based methods.\
    \ All of their implementations are from the OpenDP library [Sma23]. To demonstrate\
    \ the scalability of our approach, we conduct an additional experiment on the\
    \ home-credit dataset [MOK18]. This dataset has 307,511 data points and 104 features.\
    \ We apply GEM [LVW21] to this high-dimensional dataset for generating synthetic\
    \ data. We pre-process each dataset to convert categorical columns into numerical\
    \ features and standardize all features to the range [0 \u21AA 1].\n\nWe clarify\
    \ that our objective is not to compare the quality of synthetic data generated\
    \ by these DP mechanisms (for a benchmark evaluation, please refer to [TMH + 21]),\
    \ but to demonstrate how our post-processing method can consistently improve the\
    \ utility of synthetic data generated from these different DP mechanisms.\n\n\
    Setup. We compare synthetic data produced by different privacy mechanisms with\
    \ \u03F5 \u2208 \xB6 2 \u21AA 4 \u2666 against the post-processed synthetic data\
    \ that are generated by applying our post-processing technique with \u03F5$_{post}$\
    \ =1 to synthetic data generated from privacy mechanisms with \u03F5 \u2208 \xB6\
    \ 1 \u21AA 3 \u2666. For UCI datasets, we select 5 features, including the target\
    \ variable, from the synthetic data that have the highest absolute correlation\
    \ with the target variable. These features are chosen as they have a higher influence\
    \ on downstream prediction tasks. The set of these features is denoted by S \u2286\
    \ [d]. Next, we define the utility measures as the first-order and second-order\
    \ moment queries among the features in S : Q = \xB6 q$_{i}$ (x) = x$_{i}$ \u2666\
    \ i \u2208 S \u222A \xB6 q$_{i\u21AAj}$ (x) = x$_{i}$x$_{j}$ \u2666 i\u21AAj \u2208\
    \ S. For home-credit dataset, we follow the same setup but choosing 10 features.\n\
    \nWe apply the Gaussian mechanism with (\u03F5$_{post}$ =1 \u21AA \u03B4$_{post}$\
    \ =1 \u25C1n $^{2}$) to estimate utility measures from the real data, where n\
    \ denotes the number of real data points. Finally, we apply Algorithm 1 with \u03B3\
    \ = 1 e-5, a batch size of 256 for UCI datasets and 4096 for home-credit, and\
    \ 200 epochs to compute the optimal resampling weights, which are then used to\
    \ resample from the synthetic data with the same sample size. We repeat our experiment\
    \ 5 times to obtain an error bar for each evaluation measure.\n\nEvaluation measure.\
    \ We provide evaluation metrics for assessing the quality of synthetic data after\
    \ post-processing. Our first metric, utility improvement, is defined as:\n\nThe\
    \ range of this metric is (-\u221E \u21AA 1], where a value of 1 indicates a perfect\
    \ alignment between the correlation matrix of the post-processed data and the\
    \ real data.\n\nTo assess the downstream quality of synthetic data, we train predictive\
    \ models using the synthetic data and then test their performance on real data.\
    \ Specifically, we split the real data, using 80% for generating synthetic data\
    \ and setting aside 20% to evaluate the performance of predictive models. We use\
    \ the synthetic data to train a logistic regression classifier to predict the\
    \ target variable based on other features. Then we apply this classifier to real\
    \ data and calculate its F1 score. We use the function BinaryLogisticRegression\
    \ from SDMetrics library [Dat23] to implement this process.\n\nWe compute two\
    \ statistical measures to quantify the similarity between synthetic and real data\
    \ distributions. The first measure is the average Jensen-Shannon distance between\
    \ the marginal distributions of synthetic and real data, which ranges from 0 (identical\
    \ distribution) to 1 (totally different distributions). The second measure is\
    \ the average inverse KL-divergence between the marginal distributions of synthetic\
    \ and real data, which ranges from 0 (totally different distributions) to 1 (identical\
    \ distribution). These statistical measures are implemented by using synthcity\
    \ library [QCvdS23].\n"
  question: List the experimental parameter settings for running Algorithm 1. Display
    the result in Markdown format.
- answer: '| Metric | Description | Range |

    |---|---|---|

    | Average Jensen-Shannon Distance | Measures similarity between marginal distributions
    | 0 (identical) to 1 (totally different) |

    | Average Inverse KL-Divergence | Measures similarity between marginal distributions
    | 0 (totally different) to 1 (identical) |

    '
  context: "data across multiple datasets and state-of-the-art privacy mechanisms.\
    \ Additionally, it achieves this without degrading the performance of downstream\
    \ models or statistical metrics. We provide additional experimental results and\
    \ implementation details in Appendix C.\n\nBenchmark. We evaluate our algorithm\
    \ on four benchmark datasets: Adult, Bank, Mushroom, and Shopping, which are from\
    \ the UCI machine learning repository [DG17]. All the datasets have a target variable\
    \ that can be used for a downstream prediction task. We use four existing DP mechanisms-AIM\
    \ [MMSM22], MST [MMS21], DPCTGAN [RLP + 20], and PATECTGAN [RLP + 20]to generate\
    \ private synthetic data. Among these DP mechanisms, AIM is a workload-based method;\
    \ MST is a marginal-based method; DPCTGAN and PATECTGAN are GAN-based methods.\
    \ All of their implementations are from the OpenDP library [Sma23]. To demonstrate\
    \ the scalability of our approach, we conduct an additional experiment on the\
    \ home-credit dataset [MOK18]. This dataset has 307,511 data points and 104 features.\
    \ We apply GEM [LVW21] to this high-dimensional dataset for generating synthetic\
    \ data. We pre-process each dataset to convert categorical columns into numerical\
    \ features and standardize all features to the range [0 \u21AA 1].\n\nWe clarify\
    \ that our objective is not to compare the quality of synthetic data generated\
    \ by these DP mechanisms (for a benchmark evaluation, please refer to [TMH + 21]),\
    \ but to demonstrate how our post-processing method can consistently improve the\
    \ utility of synthetic data generated from these different DP mechanisms.\n\n\
    Setup. We compare synthetic data produced by different privacy mechanisms with\
    \ \u03F5 \u2208 \xB6 2 \u21AA 4 \u2666 against the post-processed synthetic data\
    \ that are generated by applying our post-processing technique with \u03F5$_{post}$\
    \ =1 to synthetic data generated from privacy mechanisms with \u03F5 \u2208 \xB6\
    \ 1 \u21AA 3 \u2666. For UCI datasets, we select 5 features, including the target\
    \ variable, from the synthetic data that have the highest absolute correlation\
    \ with the target variable. These features are chosen as they have a higher influence\
    \ on downstream prediction tasks. The set of these features is denoted by S \u2286\
    \ [d]. Next, we define the utility measures as the first-order and second-order\
    \ moment queries among the features in S : Q = \xB6 q$_{i}$ (x) = x$_{i}$ \u2666\
    \ i \u2208 S \u222A \xB6 q$_{i\u21AAj}$ (x) = x$_{i}$x$_{j}$ \u2666 i\u21AAj \u2208\
    \ S. For home-credit dataset, we follow the same setup but choosing 10 features.\n\
    \nWe apply the Gaussian mechanism with (\u03F5$_{post}$ =1 \u21AA \u03B4$_{post}$\
    \ =1 \u25C1n $^{2}$) to estimate utility measures from the real data, where n\
    \ denotes the number of real data points. Finally, we apply Algorithm 1 with \u03B3\
    \ = 1 e-5, a batch size of 256 for UCI datasets and 4096 for home-credit, and\
    \ 200 epochs to compute the optimal resampling weights, which are then used to\
    \ resample from the synthetic data with the same sample size. We repeat our experiment\
    \ 5 times to obtain an error bar for each evaluation measure.\n\nEvaluation measure.\
    \ We provide evaluation metrics for assessing the quality of synthetic data after\
    \ post-processing. Our first metric, utility improvement, is defined as:\n\nThe\
    \ range of this metric is (-\u221E \u21AA 1], where a value of 1 indicates a perfect\
    \ alignment between the correlation matrix of the post-processed data and the\
    \ real data.\n\nTo assess the downstream quality of synthetic data, we train predictive\
    \ models using the synthetic data and then test their performance on real data.\
    \ Specifically, we split the real data, using 80% for generating synthetic data\
    \ and setting aside 20% to evaluate the performance of predictive models. We use\
    \ the synthetic data to train a logistic regression classifier to predict the\
    \ target variable based on other features. Then we apply this classifier to real\
    \ data and calculate its F1 score. We use the function BinaryLogisticRegression\
    \ from SDMetrics library [Dat23] to implement this process.\n\nWe compute two\
    \ statistical measures to quantify the similarity between synthetic and real data\
    \ distributions. The first measure is the average Jensen-Shannon distance between\
    \ the marginal distributions of synthetic and real data, which ranges from 0 (identical\
    \ distribution) to 1 (totally different distributions). The second measure is\
    \ the average inverse KL-divergence between the marginal distributions of synthetic\
    \ and real data, which ranges from 0 (totally different distributions) to 1 (identical\
    \ distribution). These statistical measures are implemented by using synthcity\
    \ library [QCvdS23].\n"
  question: 'List metrics used to measure the distance between synthetic data and
    real data. For each metric, list the name, description and range of value. Display
    the result in Markdown format.

    '
task_description: 'extracting content from a technical paper and providing it in markdown
  format

  '
