created_by: IBM
seed_examples:
- answer: 'Datasets used for this paper:

    - Adult

    - Mushroom

    - Shopper

    - Bank

    - Home-credit

    '
  context: "Table 1: We compare synthetic data generated without and with our post-processing\
    \ technique, all under the same privacy budget \u03F5 =2. We demonstrate utility\
    \ improvement (higher is better, positive numbers imply improvement) and F1 score\
    \ for downstream models trained on synthetic data and tested on real data. For\
    \ reference, when training the same downstream model using real data, the F1 scores\
    \ are: (Adult \u21AA 0 \xB1 61), (Mushroom \u21AA 0 \xB1 95), (Shopper \u21AA\
    \ 0 \xB1 54), and (Bank \u21AA 0 \xB1 47). Additionally, we measure the average\
    \ Jensen-Shannon (JS) distance between the marginal distributions of synthetic\
    \ and real data (0: identical distribution; 1: totally different distributions)\
    \ and the average inverse KL-divergence (0: totally different distributions; 1:\
    \ identical distribution). As shown, our technique consistently improves the utility\
    \ of the synthetic data across all datasets and all DP mechanisms without degrading\
    \ the performance of downstream models or statistical metrics.\n\n|\_\_\_\_\_\
    |\_\_\_\_\_\_\_|\_\_\_\_\_\_\_\_\_| F1 score\_\_\_\_| F1 score\_\_\_\_\_| JS distance\
    \ (marginal)\_\_| JS distance (marginal)\_\_| Inverse KL (marginal)\_\_| Inverse\
    \ KL (marginal)\_\_|\n|----------|--------------|-----------------|----------------|-------------------|--------------------------|--------------------------|-------------------------|-------------------------|\n\
    | Dataset\_| DP Mechanism | Utility Improv. | w/o post-proc. | w/ post-proc.\_\
    \_\_| w/o post-proc.\_\_\_\_\_\_| w/ post-proc.\_\_\_\_\_\_| w/o post-proc.\_\_\
    \_\_\_| w/ post-proc.\_\_\_\_\_\_|\n| Adult\_\_| AIM\_\_\_\_\_| 0.13 \xB7 0 \xB1\
    \ 03\_\_| 0.61\_\_\_\_\_\_| 0.61\xB7 0 \xB1 0\_| 0.01\_\_\_\_\_\_\_\_\_\_\_| 0\xB7\
    \ 0 \xB1 0\_\_\_\_\_\_| 0.99\_\_\_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\_\_\_\_\_|\n\
    |\_\_\_\_\_| MST\_\_\_\_\_| 0.22 \xB7 0 \xB1 02\_\_| 0.55\_\_\_\_\_\_| 0.56\xB7\
    \ 0 \xB1 0\_| 0.01\_\_\_\_\_\_\_\_\_\_\_| 0\xB7 0 \xB1 0\_\_\_\_\_\_| 1\_\_\_\_\
    \_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_| DPCTGAN\_\_\_| 0.81\
    \ \xB7 0 \xB1 09\_\_| 0.22\_\_\_\_\_\_| 0.33\xB7 0 \xB1 02 | 0.07\_\_\_\_\_\_\_\
    \_\_\_\_| 0.03\xB7 0 \xB1 02\_\_\_\_| 0.85\_\_\_\_\_\_\_\_\_\_| 0.91\xB7 0 \xB1\
    \ 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\_| 0.6 \xB7 0 \xB1 04\_\_| 0.37\_\_\_\_\
    \_\_| 0.5\xB7 0 \xB1 03\_| 0.04\_\_\_\_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\
    \_\_| 0.72\_\_\_\_\_\_\_\_\_\_| 0.87\xB7 0 \xB1 0\_\_\_\_|\n| Mushroom | AIM\_\
    \_\_\_\_| 0.12 \xB7 0 \xB1 0\_\_| 0.93\_\_\_\_\_\_| 0.93\xB7 0 \xB1 0\_| 0.01\_\
    \_\_\_\_\_\_\_\_\_\_| 0\xB7 0 \xB1 0\_\_\_\_\_\_| 1\_\_\_\_\_\_\_\_\_\_\_\_| 1\xB7\
    \ 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_| MST\_\_\_\_\_| 0.58 \xB7 0 \xB1 0\_\_| 0.83\_\
    \_\_\_\_\_| 0.83\xB7 0 \xB1 02 | 0.01\_\_\_\_\_\_\_\_\_\_\_| 0\xB7 0 \xB1 0\_\_\
    \_\_\_\_| 1\_\_\_\_\_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_\
    | DPCTGAN\_\_\_| 0.69 \xB7 0 \xB1 04\_\_| 0.47\_\_\_\_\_\_| 0.68\xB7 0 \xB1 01\
    \ | 0.05\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7 0 \xB1 0\_\_\_\_\_| 0.83\_\_\_\_\_\_\_\
    \_\_\_| 0.92\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\_| 0.83 \xB7 0 \xB1\
    \ 05\_\_| 0.6\_\_\_\_\_\_| 0.86\xB7 0 \xB1 04 | 0.03\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7\
    \ 0 \xB1 0\_\_\_\_\_| 0.87\_\_\_\_\_\_\_\_\_\_| 0.95\xB7 0 \xB1 0\_\_\_\_|\n|\
    \ Shopper\_| AIM\_\_\_\_\_| 0.1 \xB7 0 \xB1 02\_\_| 0.48\_\_\_\_\_\_| 0.48\xB7\
    \ 0 \xB1 02 | 0.02\_\_\_\_\_\_\_\_\_\_\_| 0.01\_\_\_\_\_\_\_\_\_\_\_| 0.84\_\_\
    \_\_\_\_\_\_\_\_| 0.92\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| MST\_\_\_\_\_| 0.5\
    \ \xB7 0 \xB1 02\_\_| 0.42\_\_\_\_\_\_| 0.47\xB7 0 \xB1 02 | 0.01\_\_\_\_\_\_\_\
    \_\_\_\_| 0\xB7 0 \xB1 0\_\_\_\_\_\_| 0.99\_\_\_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\
    \_\_\_\_\_|\n|\_\_\_\_\_| DPCTGAN\_\_\_| 0.36 \xB7 0 \xB1 05\_\_| 0.27\_\_\_\_\
    \_\_| 0.3\xB7 0 \xB1 02\_| 0.03\_\_\_\_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\
    \_\_| 0.74\_\_\_\_\_\_\_\_\_\_| 0.85\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\
    \_| 0.11 \xB7 0 \xB1 04\_\_| 0.25\_\_\_\_\_\_| 0.31\xB7 0 \xB1 05 | 0.04\_\_\_\
    \_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\_\_| 0.8\_\_\_\_\_\_\_\_\_\_\_| 0.89\xB7\
    \ 0 \xB1 0\_\_\_\_|\n| Bank\_\_\_| AIM\_\_\_\_\_| 0.18 \xB7 0 \xB1 01\_\_| 0.45\_\
    \_\_\_\_\_| 0.46\xB7 0 \xB1 01 | 0.04\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7 0 \xB1 01\_\
    \_\_\_| 0.83\_\_\_\_\_\_\_\_\_\_| 0.9\xB7 0 \xB1 0\_\_\_\_\_|\n|\_\_\_\_\_| MST\_\
    \_\_\_\_| 0.32 \xB7 0 \xB1 02\_\_| 0.43\_\_\_\_\_\_| 0.44\xB7 0 \xB1 02 | 0.02\_\
    \_\_\_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\_\_| 0.98\_\_\_\_\_\_\_\_\_\_| 1\xB7\
    \ 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_| DPCTGAN\_\_\_| 0.2 \xB7 0 \xB1 02\_\_| 0.22\_\
    \_\_\_\_\_| 0.24\xB7 0 \xB1 07 | 0.04\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7 0 \xB1 01\_\
    \_\_\_| 0.71\_\_\_\_\_\_\_\_\_\_| 0.88\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\
    \_| 0.25 \xB7 0 \xB1 03\_\_| 0.2\_\_\_\_\_\_| 0.23\xB7 0 \xB1 05 | 0.03\_\_\_\_\
    \_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\_\_| 0.83\_\_\_\_\_\_\_\_\_\_| 0.9\xB7\
    \ 0 \xB1 0\_\_\_\_\_|\n\nTable 2: Experimental results on the home-credit dataset.\
    \ We compare synthetic data produced by GEM with \u03F5 \u2208 \xB6 2 \u21AA 4\
    \ \u2666 against the post-processed synthetic data that are generated by applying\
    \ our post-processing technique with \u03F5$_{post =1 to synthetic data generated\
    \ from GEM with \u03F5 \u2208 \xB6 1 \u21AA 3 \u2666. For reference, the downstream\
    \ model trained and tested on real data has an F1 score of 0 \xB1 24.\n\n| DP\
    \ Mechanism\_\_| Utility Improv.\_\_|\_\_F1 score w/o post-proc. | F1 score w/\
    \ post-proc.\_\_|\_\_JS distance w/o post-proc. | JS distance w/ post-proc.\_\_\
    |\_\_Inverse KL w/o post-proc. | Inverse KL w/ post-proc.\_\_|\n|----------------|-------------------|---------------------------|--------------------------|------------------------------|-----------------------------|-----------------------------|----------------------------|\n\
    | GEM \u03F5 =2\_\_\_\_| 0.57 \xB7 0 \xB1 03\_\_\_|\_\_\_\_\_\_\_\_\_\_\_0.19\
    \ | 0.19\xB7 0 \xB1 02\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_\_0.01 | 0.01\xB7 0 \xB1\
    \ 0\_\_\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_0.93 | 0.97\xB7 0 \xB1 01\_\_\_\_\_|\n\
    | GEM \u03F5 =4\_\_\_\_| 0.68 \xB7 0 \xB1 01\_\_\_|\_\_\_\_\_\_\_\_\_\_\_0.21\
    \ | 0.21\xB7 0 \xB1 01\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_\_0.01 | 0.01\xB7 0 \xB1\
    \ 0\_\_\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_0.95 | 0.99\xB7 0 \xB1 01\_\_\_\_\_|\n\
    \nResult. We present the experimental results on the UCI datasets in Table 1 (and\
    \ Table 3 in Appendix C with a higher privacy budget). We report utility improvement,\
    \ F1 score, and statistical measures. As shown, our post-processing technique\
    \ consistently enhances the utility of synthetic data on selected metrics across\
    \ all benchmark datasets and all privacy mechanisms. Moreover, the utility improvements\
    \ are achieved without degrading the performance of downstream models or statistical\
    \ properties of synthetic data. In other words, our post-processing procedure\
    \ ensures that the logistic regression classifier trained on synthetic data can\
    \ achieve comparable or even higher performance on real test data, while simultaneously\
    \ reducing or maintaining the statistical divergences between synthetic and real\
    \ data.\n\nWe present the experimental results on the home-credit dataset in Table\
    \ 2 and illustrate the misalignment of the correlation matrix with and without\
    \ applying our post-processing procedure in Figure 1. The results demonstrate\
    \ that our algorithm consistently reduces the overall correlation misalignment.\
    \ Additionally, our procedure, which includes computing the utility measures from\
    \ real data, denoising the noisy answers, and computing optimal resampling weights,\
    \ only takes around 4 mins on 1x NVIDIA GeForce RTX 3090 GPU.\n"
  question: 'List all the datasets used in this paper in bullet format.

    '
- answer: 'DP Mechanism:

    - AIM

    - MST

    - DPCTGAN

    - PATECTGAN

    - GEM

    '
  context: "Table 1: We compare synthetic data generated without and with our post-processing\
    \ technique, all under the same privacy budget \u03F5 =2. We demonstrate utility\
    \ improvement (higher is better, positive numbers imply improvement) and F1 score\
    \ for downstream models trained on synthetic data and tested on real data. For\
    \ reference, when training the same downstream model using real data, the F1 scores\
    \ are: (Adult \u21AA 0 \xB1 61), (Mushroom \u21AA 0 \xB1 95), (Shopper \u21AA\
    \ 0 \xB1 54), and (Bank \u21AA 0 \xB1 47). Additionally, we measure the average\
    \ Jensen-Shannon (JS) distance between the marginal distributions of synthetic\
    \ and real data (0: identical distribution; 1: totally different distributions)\
    \ and the average inverse KL-divergence (0: totally different distributions; 1:\
    \ identical distribution). As shown, our technique consistently improves the utility\
    \ of the synthetic data across all datasets and all DP mechanisms without degrading\
    \ the performance of downstream models or statistical metrics.\n\n|\_\_\_\_\_\
    |\_\_\_\_\_\_\_|\_\_\_\_\_\_\_\_\_| F1 score\_\_\_\_| F1 score\_\_\_\_\_| JS distance\
    \ (marginal)\_\_| JS distance (marginal)\_\_| Inverse KL (marginal)\_\_| Inverse\
    \ KL (marginal)\_\_|\n|----------|--------------|-----------------|----------------|-------------------|--------------------------|--------------------------|-------------------------|-------------------------|\n\
    | Dataset\_| DP Mechanism | Utility Improv. | w/o post-proc. | w/ post-proc.\_\
    \_\_| w/o post-proc.\_\_\_\_\_\_| w/ post-proc.\_\_\_\_\_\_| w/o post-proc.\_\_\
    \_\_\_| w/ post-proc.\_\_\_\_\_\_|\n| Adult\_\_| AIM\_\_\_\_\_| 0.13 \xB7 0 \xB1\
    \ 03\_\_| 0.61\_\_\_\_\_\_| 0.61\xB7 0 \xB1 0\_| 0.01\_\_\_\_\_\_\_\_\_\_\_| 0\xB7\
    \ 0 \xB1 0\_\_\_\_\_\_| 0.99\_\_\_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\_\_\_\_\_|\n\
    |\_\_\_\_\_| MST\_\_\_\_\_| 0.22 \xB7 0 \xB1 02\_\_| 0.55\_\_\_\_\_\_| 0.56\xB7\
    \ 0 \xB1 0\_| 0.01\_\_\_\_\_\_\_\_\_\_\_| 0\xB7 0 \xB1 0\_\_\_\_\_\_| 1\_\_\_\_\
    \_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_| DPCTGAN\_\_\_| 0.81\
    \ \xB7 0 \xB1 09\_\_| 0.22\_\_\_\_\_\_| 0.33\xB7 0 \xB1 02 | 0.07\_\_\_\_\_\_\_\
    \_\_\_\_| 0.03\xB7 0 \xB1 02\_\_\_\_| 0.85\_\_\_\_\_\_\_\_\_\_| 0.91\xB7 0 \xB1\
    \ 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\_| 0.6 \xB7 0 \xB1 04\_\_| 0.37\_\_\_\_\
    \_\_| 0.5\xB7 0 \xB1 03\_| 0.04\_\_\_\_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\
    \_\_| 0.72\_\_\_\_\_\_\_\_\_\_| 0.87\xB7 0 \xB1 0\_\_\_\_|\n| Mushroom | AIM\_\
    \_\_\_\_| 0.12 \xB7 0 \xB1 0\_\_| 0.93\_\_\_\_\_\_| 0.93\xB7 0 \xB1 0\_| 0.01\_\
    \_\_\_\_\_\_\_\_\_\_| 0\xB7 0 \xB1 0\_\_\_\_\_\_| 1\_\_\_\_\_\_\_\_\_\_\_\_| 1\xB7\
    \ 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_| MST\_\_\_\_\_| 0.58 \xB7 0 \xB1 0\_\_| 0.83\_\
    \_\_\_\_\_| 0.83\xB7 0 \xB1 02 | 0.01\_\_\_\_\_\_\_\_\_\_\_| 0\xB7 0 \xB1 0\_\_\
    \_\_\_\_| 1\_\_\_\_\_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_\
    | DPCTGAN\_\_\_| 0.69 \xB7 0 \xB1 04\_\_| 0.47\_\_\_\_\_\_| 0.68\xB7 0 \xB1 01\
    \ | 0.05\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7 0 \xB1 0\_\_\_\_\_| 0.83\_\_\_\_\_\_\_\
    \_\_\_| 0.92\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\_| 0.83 \xB7 0 \xB1\
    \ 05\_\_| 0.6\_\_\_\_\_\_| 0.86\xB7 0 \xB1 04 | 0.03\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7\
    \ 0 \xB1 0\_\_\_\_\_| 0.87\_\_\_\_\_\_\_\_\_\_| 0.95\xB7 0 \xB1 0\_\_\_\_|\n|\
    \ Shopper\_| AIM\_\_\_\_\_| 0.1 \xB7 0 \xB1 02\_\_| 0.48\_\_\_\_\_\_| 0.48\xB7\
    \ 0 \xB1 02 | 0.02\_\_\_\_\_\_\_\_\_\_\_| 0.01\_\_\_\_\_\_\_\_\_\_\_| 0.84\_\_\
    \_\_\_\_\_\_\_\_| 0.92\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| MST\_\_\_\_\_| 0.5\
    \ \xB7 0 \xB1 02\_\_| 0.42\_\_\_\_\_\_| 0.47\xB7 0 \xB1 02 | 0.01\_\_\_\_\_\_\_\
    \_\_\_\_| 0\xB7 0 \xB1 0\_\_\_\_\_\_| 0.99\_\_\_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\
    \_\_\_\_\_|\n|\_\_\_\_\_| DPCTGAN\_\_\_| 0.36 \xB7 0 \xB1 05\_\_| 0.27\_\_\_\_\
    \_\_| 0.3\xB7 0 \xB1 02\_| 0.03\_\_\_\_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\
    \_\_| 0.74\_\_\_\_\_\_\_\_\_\_| 0.85\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\
    \_| 0.11 \xB7 0 \xB1 04\_\_| 0.25\_\_\_\_\_\_| 0.31\xB7 0 \xB1 05 | 0.04\_\_\_\
    \_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\_\_| 0.8\_\_\_\_\_\_\_\_\_\_\_| 0.89\xB7\
    \ 0 \xB1 0\_\_\_\_|\n| Bank\_\_\_| AIM\_\_\_\_\_| 0.18 \xB7 0 \xB1 01\_\_| 0.45\_\
    \_\_\_\_\_| 0.46\xB7 0 \xB1 01 | 0.04\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7 0 \xB1 01\_\
    \_\_\_| 0.83\_\_\_\_\_\_\_\_\_\_| 0.9\xB7 0 \xB1 0\_\_\_\_\_|\n|\_\_\_\_\_| MST\_\
    \_\_\_\_| 0.32 \xB7 0 \xB1 02\_\_| 0.43\_\_\_\_\_\_| 0.44\xB7 0 \xB1 02 | 0.02\_\
    \_\_\_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\_\_| 0.98\_\_\_\_\_\_\_\_\_\_| 1\xB7\
    \ 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_| DPCTGAN\_\_\_| 0.2 \xB7 0 \xB1 02\_\_| 0.22\_\
    \_\_\_\_\_| 0.24\xB7 0 \xB1 07 | 0.04\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7 0 \xB1 01\_\
    \_\_\_| 0.71\_\_\_\_\_\_\_\_\_\_| 0.88\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\
    \_| 0.25 \xB7 0 \xB1 03\_\_| 0.2\_\_\_\_\_\_| 0.23\xB7 0 \xB1 05 | 0.03\_\_\_\_\
    \_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\_\_| 0.83\_\_\_\_\_\_\_\_\_\_| 0.9\xB7\
    \ 0 \xB1 0\_\_\_\_\_|\n\nTable 2: Experimental results on the home-credit dataset.\
    \ We compare synthetic data produced by GEM with \u03F5 \u2208 \xB6 2 \u21AA 4\
    \ \u2666 against the post-processed synthetic data that are generated by applying\
    \ our post-processing technique with \u03F5$_{post =1 to synthetic data generated\
    \ from GEM with \u03F5 \u2208 \xB6 1 \u21AA 3 \u2666. For reference, the downstream\
    \ model trained and tested on real data has an F1 score of 0 \xB1 24.\n\n| DP\
    \ Mechanism\_\_| Utility Improv.\_\_|\_\_F1 score w/o post-proc. | F1 score w/\
    \ post-proc.\_\_|\_\_JS distance w/o post-proc. | JS distance w/ post-proc.\_\_\
    |\_\_Inverse KL w/o post-proc. | Inverse KL w/ post-proc.\_\_|\n|----------------|-------------------|---------------------------|--------------------------|------------------------------|-----------------------------|-----------------------------|----------------------------|\n\
    | GEM \u03F5 =2\_\_\_\_| 0.57 \xB7 0 \xB1 03\_\_\_|\_\_\_\_\_\_\_\_\_\_\_0.19\
    \ | 0.19\xB7 0 \xB1 02\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_\_0.01 | 0.01\xB7 0 \xB1\
    \ 0\_\_\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_0.93 | 0.97\xB7 0 \xB1 01\_\_\_\_\_|\n\
    | GEM \u03F5 =4\_\_\_\_| 0.68 \xB7 0 \xB1 01\_\_\_|\_\_\_\_\_\_\_\_\_\_\_0.21\
    \ | 0.21\xB7 0 \xB1 01\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_\_0.01 | 0.01\xB7 0 \xB1\
    \ 0\_\_\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_0.95 | 0.99\xB7 0 \xB1 01\_\_\_\_\_|\n\
    \nResult. We present the experimental results on the UCI datasets in Table 1 (and\
    \ Table 3 in Appendix C with a higher privacy budget). We report utility improvement,\
    \ F1 score, and statistical measures. As shown, our post-processing technique\
    \ consistently enhances the utility of synthetic data on selected metrics across\
    \ all benchmark datasets and all privacy mechanisms. Moreover, the utility improvements\
    \ are achieved without degrading the performance of downstream models or statistical\
    \ properties of synthetic data. In other words, our post-processing procedure\
    \ ensures that the logistic regression classifier trained on synthetic data can\
    \ achieve comparable or even higher performance on real test data, while simultaneously\
    \ reducing or maintaining the statistical divergences between synthetic and real\
    \ data.\n\nWe present the experimental results on the home-credit dataset in Table\
    \ 2 and illustrate the misalignment of the correlation matrix with and without\
    \ applying our post-processing procedure in Figure 1. The results demonstrate\
    \ that our algorithm consistently reduces the overall correlation misalignment.\
    \ Additionally, our procedure, which includes computing the utility measures from\
    \ real data, denoising the noisy answers, and computing optimal resampling weights,\
    \ only takes around 4 mins on 1x NVIDIA GeForce RTX 3090 GPU.\n"
  question: What were the DP mechanisms used (in bullets)?
- answer: 'Metrics:

    - Utility improvement

    - F1 score (w/o post processing)

    - F1 score (w/ post processing)

    - JS distance (w/o post processing)

    - JS distance (w/ post-processing)

    - Inverse KL (w/o post-processing)

    - Inverse KL (w/ post-processing)

    '
  context: "Table 1: We compare synthetic data generated without and with our post-processing\
    \ technique, all under the same privacy budget \u03F5 =2. We demonstrate utility\
    \ improvement (higher is better, positive numbers imply improvement) and F1 score\
    \ for downstream models trained on synthetic data and tested on real data. For\
    \ reference, when training the same downstream model using real data, the F1 scores\
    \ are: (Adult \u21AA 0 \xB1 61), (Mushroom \u21AA 0 \xB1 95), (Shopper \u21AA\
    \ 0 \xB1 54), and (Bank \u21AA 0 \xB1 47). Additionally, we measure the average\
    \ Jensen-Shannon (JS) distance between the marginal distributions of synthetic\
    \ and real data (0: identical distribution; 1: totally different distributions)\
    \ and the average inverse KL-divergence (0: totally different distributions; 1:\
    \ identical distribution). As shown, our technique consistently improves the utility\
    \ of the synthetic data across all datasets and all DP mechanisms without degrading\
    \ the performance of downstream models or statistical metrics.\n\n|\_\_\_\_\_\
    |\_\_\_\_\_\_\_|\_\_\_\_\_\_\_\_\_| F1 score\_\_\_\_| F1 score\_\_\_\_\_| JS distance\
    \ (marginal)\_\_| JS distance (marginal)\_\_| Inverse KL (marginal)\_\_| Inverse\
    \ KL (marginal)\_\_|\n|----------|--------------|-----------------|----------------|-------------------|--------------------------|--------------------------|-------------------------|-------------------------|\n\
    | Dataset\_| DP Mechanism | Utility Improv. | w/o post-proc. | w/ post-proc.\_\
    \_\_| w/o post-proc.\_\_\_\_\_\_| w/ post-proc.\_\_\_\_\_\_| w/o post-proc.\_\_\
    \_\_\_| w/ post-proc.\_\_\_\_\_\_|\n| Adult\_\_| AIM\_\_\_\_\_| 0.13 \xB7 0 \xB1\
    \ 03\_\_| 0.61\_\_\_\_\_\_| 0.61\xB7 0 \xB1 0\_| 0.01\_\_\_\_\_\_\_\_\_\_\_| 0\xB7\
    \ 0 \xB1 0\_\_\_\_\_\_| 0.99\_\_\_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\_\_\_\_\_|\n\
    |\_\_\_\_\_| MST\_\_\_\_\_| 0.22 \xB7 0 \xB1 02\_\_| 0.55\_\_\_\_\_\_| 0.56\xB7\
    \ 0 \xB1 0\_| 0.01\_\_\_\_\_\_\_\_\_\_\_| 0\xB7 0 \xB1 0\_\_\_\_\_\_| 1\_\_\_\_\
    \_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_| DPCTGAN\_\_\_| 0.81\
    \ \xB7 0 \xB1 09\_\_| 0.22\_\_\_\_\_\_| 0.33\xB7 0 \xB1 02 | 0.07\_\_\_\_\_\_\_\
    \_\_\_\_| 0.03\xB7 0 \xB1 02\_\_\_\_| 0.85\_\_\_\_\_\_\_\_\_\_| 0.91\xB7 0 \xB1\
    \ 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\_| 0.6 \xB7 0 \xB1 04\_\_| 0.37\_\_\_\_\
    \_\_| 0.5\xB7 0 \xB1 03\_| 0.04\_\_\_\_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\
    \_\_| 0.72\_\_\_\_\_\_\_\_\_\_| 0.87\xB7 0 \xB1 0\_\_\_\_|\n| Mushroom | AIM\_\
    \_\_\_\_| 0.12 \xB7 0 \xB1 0\_\_| 0.93\_\_\_\_\_\_| 0.93\xB7 0 \xB1 0\_| 0.01\_\
    \_\_\_\_\_\_\_\_\_\_| 0\xB7 0 \xB1 0\_\_\_\_\_\_| 1\_\_\_\_\_\_\_\_\_\_\_\_| 1\xB7\
    \ 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_| MST\_\_\_\_\_| 0.58 \xB7 0 \xB1 0\_\_| 0.83\_\
    \_\_\_\_\_| 0.83\xB7 0 \xB1 02 | 0.01\_\_\_\_\_\_\_\_\_\_\_| 0\xB7 0 \xB1 0\_\_\
    \_\_\_\_| 1\_\_\_\_\_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_\
    | DPCTGAN\_\_\_| 0.69 \xB7 0 \xB1 04\_\_| 0.47\_\_\_\_\_\_| 0.68\xB7 0 \xB1 01\
    \ | 0.05\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7 0 \xB1 0\_\_\_\_\_| 0.83\_\_\_\_\_\_\_\
    \_\_\_| 0.92\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\_| 0.83 \xB7 0 \xB1\
    \ 05\_\_| 0.6\_\_\_\_\_\_| 0.86\xB7 0 \xB1 04 | 0.03\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7\
    \ 0 \xB1 0\_\_\_\_\_| 0.87\_\_\_\_\_\_\_\_\_\_| 0.95\xB7 0 \xB1 0\_\_\_\_|\n|\
    \ Shopper\_| AIM\_\_\_\_\_| 0.1 \xB7 0 \xB1 02\_\_| 0.48\_\_\_\_\_\_| 0.48\xB7\
    \ 0 \xB1 02 | 0.02\_\_\_\_\_\_\_\_\_\_\_| 0.01\_\_\_\_\_\_\_\_\_\_\_| 0.84\_\_\
    \_\_\_\_\_\_\_\_| 0.92\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| MST\_\_\_\_\_| 0.5\
    \ \xB7 0 \xB1 02\_\_| 0.42\_\_\_\_\_\_| 0.47\xB7 0 \xB1 02 | 0.01\_\_\_\_\_\_\_\
    \_\_\_\_| 0\xB7 0 \xB1 0\_\_\_\_\_\_| 0.99\_\_\_\_\_\_\_\_\_\_| 1\xB7 0 \xB1 0\_\
    \_\_\_\_\_|\n|\_\_\_\_\_| DPCTGAN\_\_\_| 0.36 \xB7 0 \xB1 05\_\_| 0.27\_\_\_\_\
    \_\_| 0.3\xB7 0 \xB1 02\_| 0.03\_\_\_\_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\
    \_\_| 0.74\_\_\_\_\_\_\_\_\_\_| 0.85\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\
    \_| 0.11 \xB7 0 \xB1 04\_\_| 0.25\_\_\_\_\_\_| 0.31\xB7 0 \xB1 05 | 0.04\_\_\_\
    \_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\_\_| 0.8\_\_\_\_\_\_\_\_\_\_\_| 0.89\xB7\
    \ 0 \xB1 0\_\_\_\_|\n| Bank\_\_\_| AIM\_\_\_\_\_| 0.18 \xB7 0 \xB1 01\_\_| 0.45\_\
    \_\_\_\_\_| 0.46\xB7 0 \xB1 01 | 0.04\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7 0 \xB1 01\_\
    \_\_\_| 0.83\_\_\_\_\_\_\_\_\_\_| 0.9\xB7 0 \xB1 0\_\_\_\_\_|\n|\_\_\_\_\_| MST\_\
    \_\_\_\_| 0.32 \xB7 0 \xB1 02\_\_| 0.43\_\_\_\_\_\_| 0.44\xB7 0 \xB1 02 | 0.02\_\
    \_\_\_\_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\_\_| 0.98\_\_\_\_\_\_\_\_\_\_| 1\xB7\
    \ 0 \xB1 0\_\_\_\_\_\_|\n|\_\_\_\_\_| DPCTGAN\_\_\_| 0.2 \xB7 0 \xB1 02\_\_| 0.22\_\
    \_\_\_\_\_| 0.24\xB7 0 \xB1 07 | 0.04\_\_\_\_\_\_\_\_\_\_\_| 0.02\xB7 0 \xB1 01\_\
    \_\_\_| 0.71\_\_\_\_\_\_\_\_\_\_| 0.88\xB7 0 \xB1 0\_\_\_\_|\n|\_\_\_\_\_| PATECTGAN\_\
    \_| 0.25 \xB7 0 \xB1 03\_\_| 0.2\_\_\_\_\_\_| 0.23\xB7 0 \xB1 05 | 0.03\_\_\_\_\
    \_\_\_\_\_\_\_| 0.01\xB7 0 \xB1 0\_\_\_\_\_| 0.83\_\_\_\_\_\_\_\_\_\_| 0.9\xB7\
    \ 0 \xB1 0\_\_\_\_\_|\n\nTable 2: Experimental results on the home-credit dataset.\
    \ We compare synthetic data produced by GEM with \u03F5 \u2208 \xB6 2 \u21AA 4\
    \ \u2666 against the post-processed synthetic data that are generated by applying\
    \ our post-processing technique with \u03F5$_{post =1 to synthetic data generated\
    \ from GEM with \u03F5 \u2208 \xB6 1 \u21AA 3 \u2666. For reference, the downstream\
    \ model trained and tested on real data has an F1 score of 0 \xB1 24.\n\n| DP\
    \ Mechanism\_\_| Utility Improv.\_\_|\_\_F1 score w/o post-proc. | F1 score w/\
    \ post-proc.\_\_|\_\_JS distance w/o post-proc. | JS distance w/ post-proc.\_\_\
    |\_\_Inverse KL w/o post-proc. | Inverse KL w/ post-proc.\_\_|\n|----------------|-------------------|---------------------------|--------------------------|------------------------------|-----------------------------|-----------------------------|----------------------------|\n\
    | GEM \u03F5 =2\_\_\_\_| 0.57 \xB7 0 \xB1 03\_\_\_|\_\_\_\_\_\_\_\_\_\_\_0.19\
    \ | 0.19\xB7 0 \xB1 02\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_\_0.01 | 0.01\xB7 0 \xB1\
    \ 0\_\_\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_0.93 | 0.97\xB7 0 \xB1 01\_\_\_\_\_|\n\
    | GEM \u03F5 =4\_\_\_\_| 0.68 \xB7 0 \xB1 01\_\_\_|\_\_\_\_\_\_\_\_\_\_\_0.21\
    \ | 0.21\xB7 0 \xB1 01\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_\_0.01 | 0.01\xB7 0 \xB1\
    \ 0\_\_\_\_\_\_|\_\_\_\_\_\_\_\_\_\_\_\_0.95 | 0.99\xB7 0 \xB1 01\_\_\_\_\_|\n\
    \nResult. We present the experimental results on the UCI datasets in Table 1 (and\
    \ Table 3 in Appendix C with a higher privacy budget). We report utility improvement,\
    \ F1 score, and statistical measures. As shown, our post-processing technique\
    \ consistently enhances the utility of synthetic data on selected metrics across\
    \ all benchmark datasets and all privacy mechanisms. Moreover, the utility improvements\
    \ are achieved without degrading the performance of downstream models or statistical\
    \ properties of synthetic data. In other words, our post-processing procedure\
    \ ensures that the logistic regression classifier trained on synthetic data can\
    \ achieve comparable or even higher performance on real test data, while simultaneously\
    \ reducing or maintaining the statistical divergences between synthetic and real\
    \ data.\n\nWe present the experimental results on the home-credit dataset in Table\
    \ 2 and illustrate the misalignment of the correlation matrix with and without\
    \ applying our post-processing procedure in Figure 1. The results demonstrate\
    \ that our algorithm consistently reduces the overall correlation misalignment.\
    \ Additionally, our procedure, which includes computing the utility measures from\
    \ real data, denoising the noisy answers, and computing optimal resampling weights,\
    \ only takes around 4 mins on 1x NVIDIA GeForce RTX 3090 GPU.\n"
  question: 'What types of metrics were calculated in table 1? Give me a list.

    '
task_description: 'extracting content from a technical paper and providing it in bulleted
  format

  '
